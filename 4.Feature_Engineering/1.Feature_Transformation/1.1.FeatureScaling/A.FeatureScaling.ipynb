{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:cyan; text-align:center; font-size:250%; font-weight:bold;\">\n",
    "Feature Scaling</h1>\n",
    "\n",
    "<h2 style=\"color: lavender; text-align:left; font-size:130%; font-weight:bold;\">\n",
    "List of the Content:\n",
    "</h2>\n",
    "        <ol style=\"font-size:120%;\">\n",
    "            <li>Standarization</li>\n",
    "            <li>Normalisation</li>\n",
    "        </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "1.1.A) Standarzarion</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "df=pd.read_csv('Social_Network_Ads.csv')\n",
    "# df.sample(5)\n",
    "df1=df[['Age', 'EstimatedSalary', 'Purchased']]\n",
    "\n",
    "# TRAIN-TEST SPLIT \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(\n",
    "    df1.drop('Purchased', axis=1), #removes 'Purchased' col from df, leaving only the features (X). \n",
    "    df1['Purchased'],      # selects the 'Purchased' column as the target variable (y)\n",
    "    test_size=0.3,         #means 30% of the data is used for testing, and 70% is used for training.\n",
    "    random_state=0)        #ensures that the split is reproducible\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "#STANDARD SCALAR \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()    #computes mean & SD for each feature in the training set and then uses those values to scale both the training and test sets.\n",
    "\n",
    "#fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(x_train) #it calculate mean&SD in for each feature in x_train\n",
    "\n",
    "#transform train and test sets (Rem: we train from only x_train but transdorm both)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "## ACCESSMENT OF SCALING \n",
    "\n",
    "#A) Crosschecking whether scalling has done or not (is mean=0 & SD=1 then done)\n",
    "x_train_scaled=pd.DataFrame(x_train_scaled, columns=x_train.columns) #convert array into DF \n",
    "x_test_scaled=pd.DataFrame(x_test_scaled, columns=x_test.columns) \n",
    "round(x_train_scaled.describe(), 2)\n",
    "\n",
    "#B) Now visualising the Distribution \n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "ax1.scatter(x_train['Age'], x_train['EstimatedSalary'])\n",
    "ax1.set_title('Before Scaling')\n",
    "ax2.scatter(x_train_scaled['Age'], x_train_scaled['EstimatedSalary'], color='r')\n",
    "ax2.set_title('After Scaling')\n",
    "# plt.show()\n",
    "\n",
    "#C) Creating Density plot: in ord\n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "sns.kdeplot(x_train['Age'], ax=ax1)\n",
    "sns.kdeplot(x_train['EstimatedSalary'], ax=ax1)\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(x_train_scaled['Age'], ax=ax2)\n",
    "sns.kdeplot(x_train_scaled['EstimatedSalary'], ax=ax2)\n",
    "ax2.set_title('After Scaling')\n",
    "\n",
    "#D) Model performance comparison before/after scalling \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr_scaled = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train,y_train)    #trained with unscaled value \n",
    "lr_scaled.fit(x_train_scaled,y_train) # trained with scaled values\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "y_pred_scaled = lr_scaled.predict(x_test_scaled)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Actual\", accuracy_score(y_test, y_pred))\n",
    "print(\"Scaled\", accuracy_score(y_test, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "1.1.B) Normalisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "df=pd.read_csv('wine.csv')\n",
    "df.sample(5)\n",
    "df=df[['Wine',\t'Alcohol', \t'Malic.acid']].rename(columns={'Wine':'Wine Class'})\n",
    "\n",
    "# TRAIN-TEST SPLIT \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(\n",
    "    df.drop('Wine Class', axis=1), #removes 'Wine class' col from df, leaving only the features (X). \n",
    "    df['Wine Class'],      # selects the 'Wine Class' column as the target variable (y)\n",
    "    test_size=0.3,         #means 30% of the data is used for testing, and 70% is used for training.\n",
    "    random_state=0)        #ensures that the split is reproducible\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Normalisarion: MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()    #computes Mean & Max for each feature in the training set and then uses those values to scale both the training and test sets.\n",
    "\n",
    "#fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(x_train) #it calculate mean&SD in for each feature in x_train\n",
    "\n",
    "#transform train and test sets (Rem: we train from only x_train but transdorm both)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "#ACCESSMENT OF SCALING \n",
    "#A) Crosschecking whether scalling has done or not (is mean=0 & SD=1 then done)\n",
    "x_train_scaled=pd.DataFrame(x_train_scaled, columns=x_train.columns) #convert array into DF \n",
    "x_test_scaled=pd.DataFrame(x_test_scaled, columns=x_test.columns) \n",
    "round(x_train_scaled.describe(), 2)\n",
    "\n",
    "#B) Now visualising the Distribution \n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "ax1.scatter(x_train['Alcohol'], x_train['Malic.acid'],c=y_train )\n",
    "ax1.set_title('Before Scaling')\n",
    "ax2.scatter(x_train_scaled['Alcohol'], x_train_scaled['Malic.acid'], c=y_train )\n",
    "ax2.set_title('After Scaling')\n",
    "# plt.show()\n",
    "\n",
    "#C) Creating Density plot: in ord\n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "sns.kdeplot(x_train['Alcohol'], ax=ax1)\n",
    "sns.kdeplot(x_train['Malic.acid'], ax=ax1)\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(x_train_scaled['Alcohol'], ax=ax2)\n",
    "sns.kdeplot(x_train_scaled['Malic.acid'], ax=ax2)\n",
    "ax2.set_title('After Scaling')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
