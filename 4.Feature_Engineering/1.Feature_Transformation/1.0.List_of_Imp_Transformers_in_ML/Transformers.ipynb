{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: cyan; text-align:center; font-size:250%; font-weight:bold;\">\n",
    "Transformers used in ML \n",
    "</h1>\n",
    "\n",
    "<h2 style=\"color: lavender; text-align:left; font-size:130%; font-weight:bold;\">\n",
    "List of the Important Transformers Used in ML\n",
    "</h2>\n",
    "\n",
    "<ol style=\"font-size:120%;\">\n",
    "    <li>Column Transformer</li>\n",
    "    <li>Pipeline</li>\n",
    "    <li>Mathemetical Transformers</li>\n",
    "    <li>Functional Transformers</li>\n",
    "    <li>Power Transformers</li>\n",
    "    <li>Quantile Transformer</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "1.Column Transformers \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset and select relevant columns\n",
    "df=pd.read_csv(\"dummy_covid_data.csv\")\n",
    "df.sample(5)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=0)\n",
    "\n",
    "#COLUMN TRANSFORMER\n",
    "transformer= ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tnf1', OrdinalEncoder(categories=[['mild', 'strong']]), ['cough']),  # Apply StandardScaler to numerical columns\n",
    "        ('fnf2', OneHotEncoder(sparse_output=False, drop='first'),['gender', 'city'])  # Apply OneHotEncoder to categorical columns\n",
    "    ]\n",
    "    , remainder='passthrough'\n",
    ")\n",
    "# Fit the transformer into the training dataset\n",
    "x_train_transform = transformer.fit_transform(x_train)\n",
    "\n",
    "# transform the test dataset \n",
    "x_test_transform=transformer.transform(x_test)\n",
    "print(x_train_transform.shape, x_test_transform.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "2.Pipeline \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#1) DATA Ingestion\n",
    "df=sns.load_dataset('titanic')\n",
    "df=df.iloc[:, 0:8]\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "\n",
    "# #Split Train-Test data split \n",
    "x_train, x_test, y_train, y_test=train_test_split(\n",
    "    df.iloc[:, 1:8],df.iloc[:, 0], test_size=0.2, random_state=0)\n",
    "x_train\n",
    "#2) Creating PIPELINE FOR TRANSFORMATION \n",
    "#Transformation: 1st define the Individual transformation then execute in sequence through pipeline  \n",
    "#     1st: Imputation transformation in age & embark ,\n",
    "#     2nd: OneHotEncoding in Sex and embark \n",
    "#     3rd: scalling all the columns \n",
    "#     4th: Feature selection \n",
    "#     5th: Train the model \n",
    "\n",
    "#2.1) IMPUTATION TRANSFORMATION \n",
    "trf1=ColumnTransformer([\n",
    "    ('impute-age', SimpleImputer(strategy='mean'), [2]), \n",
    "    ('impute-embark', SimpleImputer(strategy='most_frequent'), [6])\n",
    "], remainder='passthrough')\n",
    "\n",
    "#2.2) ONE HOT ENCODING \n",
    "trf2=ColumnTransformer([\n",
    "    ('ohe-sex-embark', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), [1, 6])\n",
    "], remainder='passthrough')\n",
    "\n",
    "#2.3) Scaling \n",
    "trf3=ColumnTransformer([\n",
    "    ('age-scaling', MinMaxScaler(), slice(0,10)) #scaling all cols after trf1&2\n",
    "]) \n",
    "\n",
    "#2.4) Feature Selections\n",
    "trf4=SelectKBest(score_func=chi2, k=8) # Selectinf 8/10 best cols \n",
    "\n",
    "#2.5) model \n",
    "trf5=DecisionTreeClassifier()\n",
    "\n",
    "#3)CREATE PIPELINE \n",
    "pipe=Pipeline([\n",
    "    ('trf1', trf1),\n",
    "    ('trf2', trf2),\n",
    "    ('trf3', trf3),\n",
    "    ('trf4', trf4),\n",
    "    ('trf5', trf5),\n",
    "])\n",
    "display(pipe)\n",
    "#4) TRAIN the model\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "#5) Predict: since model is trained we predict the value \n",
    "y_pred= pipe.predict(x_test)\n",
    "y_pred\n",
    "\n",
    "#6) CALCULATE ACCURACY \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "#7) CROSS VALIDATION using pipeline \n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, x_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "#8)HYPERTUNING Using GridsearchCV \n",
    "params={\n",
    "    'trf5__max_depth':[1,2,3,4,5, None]\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid=GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best score=\",grid.best_score_, \"Max_depth=\", grid.best_params_)\n",
    "\n",
    "#9)Exporting the PIPELINE\n",
    "import pickle\n",
    "pickle.dump(pipe, open('pipe.pkl', 'wb'))\n",
    "\n",
    "#10)CODE IN PRODUCTION \n",
    "import pickle \n",
    "import numpy as np\n",
    "pipe=pickle.load(open('pipe.pkl', 'rb'))\n",
    "#Assume user input \n",
    "test_input1 = np.array([2, 'male', 31.0, 0, 0, 10.5, 'S'], dtype='object').reshape(1,7)\n",
    "pipe.predict(test_input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "3.Mathematical Transformers\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:deeppink; text-align:left; font-size:150%; font-weight:bold;\">\n",
    "3.1.Log Transformers \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "#dataset\n",
    "data = sns.load_dataset('titanic')\n",
    "# Apply log transformation\n",
    "log_transformed_data = np.log(data['age'])\n",
    "#ploting data before and after log transformer \n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "sns.histplot(data['age'], ax=ax1,  kde=True)\n",
    "ax1.set_title('Before Transformation')\n",
    "sns.histplot(log_transformed_data, ax=ax2,  kde=True)\n",
    "ax2.set_title('After Log Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:deeppink; text-align:left; font-size:150%; font-weight:bold;\">\n",
    "3.2.Reciprocal Transformers \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "# Example data\n",
    "data = sns.load_dataset('titanic')\n",
    "# Apply log transformation\n",
    "reciprocal_transformed_data = 1/(data['age'].dropna())\n",
    "#ploting data before and after log transformer \n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "sns.histplot(data['age'].dropna(), ax=ax1, kde=True)\n",
    "ax1.set_title('Before Transformation')\n",
    "sns.histplot(log_transformed_data.dropna(),ax=ax2, kde=True)\n",
    "ax2.set_title('After Reciprocal Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:deeppink; text-align:left; font-size:150%; font-weight:bold;\">\n",
    "3.3.X-Square Transformers \n",
    "</h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "# Example data\n",
    "data = sns.load_dataset('titanic')\n",
    "# Apply x-square transformation\n",
    "square_transformed_data = (data['age'].dropna())**2\n",
    "#ploting data before and after log transformer \n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "sns.histplot(data['age'].dropna(), ax=ax1, kde=True)\n",
    "ax1.set_title('Before Transformation')\n",
    "sns.histplot(square_transformed_data.dropna(),ax=ax2, kde=True)\n",
    "ax2.set_title('After X-square Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:deeppink; text-align:left; font-size:150%; font-weight:bold;\">\n",
    "3.4.Square Root Transformers \n",
    "</h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "# Example data\n",
    "data = sns.load_dataset('titanic')\n",
    "# Apply square root transformation\n",
    "square_root_transformed_data = np.sqrt(data['age'].dropna())\n",
    "#ploting data before and after square root transformer \n",
    "fig, (ax1, ax2) =plt.subplots(ncols=2, figsize=(5,2))\n",
    "sns.histplot(data['age'].dropna(), ax=ax1, kde=True)\n",
    "ax1.set_title('Before Transformation')\n",
    "sns.histplot(square_root_transformed_data.dropna(),ax=ax2, kde=True)\n",
    "ax2.set_title('After square-root Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:deeppink; text-align:left; font-size:150%; font-weight:bold;\">\n",
    "3.5.Custom Transformers \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load example data\n",
    "data = sns.load_dataset('titanic')\n",
    "# Custom transformation function\n",
    "def custom_transform(x, threshold=30):\n",
    "    if x < threshold:\n",
    "        return np.sqrt(x)\n",
    "    else:\n",
    "        return x ** 2\n",
    "\n",
    "# Apply custom transformation to the 'age' column (handle missing values)\n",
    "custom_transformed_data = data['age'].dropna().apply(custom_transform)\n",
    "\n",
    "# Plotting data before and after custom transformation\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "\n",
    "# Original data (before transformation)\n",
    "sns.histplot(data['age'].dropna(), ax=ax1, kde=True)\n",
    "ax1.set_title('Original Age Data')\n",
    "\n",
    "# Custom transformed data (after transformation)\n",
    "sns.histplot(custom_transformed_data, ax=ax2, kde=True, color='purple')\n",
    "ax2.set_title('Custom Transformed Age Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "4.Funtional Transformers\n",
    "</h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 1) LOAD DATASET \n",
    "df=sns.load_dataset('titanic')\n",
    "df=df[['age', 'fare', 'survived']]\n",
    "df.info()\n",
    "\n",
    "#2.1) Imputation of Age \n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "df.isnull().sum() #check for Null values\n",
    "\n",
    "#2.2) Extract the X and y from df  & DO Train-test split  \n",
    "x=df.iloc[:, 0:2]\n",
    "y=df.iloc[:, -1]\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#2.3) Checking the Normality of the data then Transforming \n",
    "#Ploting age \n",
    "plt.figure(figsize=(9,2))\n",
    "plt.subplot(121)\n",
    "sns.histplot(x_train['age'], kde=True) \n",
    "plt.subplot(122)\n",
    "stats.probplot(x_train['age'], dist='norm', plot=plt)\n",
    "plt.show()\n",
    "#ploting fare \n",
    "plt.figure(figsize=(9,2))\n",
    "plt.subplot(121)\n",
    "sns.histplot(x_train['fare'], kde=True) \n",
    "plt.subplot(122)\n",
    "stats.probplot(x_train['fare'], dist='norm', plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#3) BEFORE NORMALIZATION: Fit in the model and check the accuracy \n",
    "clf1=LogisticRegression()\n",
    "clf2=DecisionTreeClassifier()\n",
    "#traing the model \n",
    "clf1.fit(x_train, y_train)\n",
    "clf2.fit(x_train, y_train)\n",
    "#prediction \n",
    "y_pred1=clf1.predict(x_test)\n",
    "y_pred2=clf2.predict(x_test)\n",
    "#calculating the accuracy \n",
    "print('LR Accuracy=', accuracy_score(y_test, y_pred1))\n",
    "print('DT Accuracy=', accuracy_score(y_test, y_pred2))\n",
    "\n",
    "#4) AFTER NORMALIZATION: Fit in the model and check the accuracy \n",
    "trf=FunctionTransformer(func=np.log1p)\n",
    "\n",
    "x_train_transform=trf.fit_transform(x_train)\n",
    "x_test_transform=trf.transform(x_test)\n",
    "\n",
    "clf1=LogisticRegression()\n",
    "clf2=DecisionTreeClassifier()\n",
    "#traing the model \n",
    "clf1.fit(x_train_transform, y_train)\n",
    "clf2.fit(x_train_transform, y_train)\n",
    "#prediction \n",
    "y_pred_tranformed1=clf1.predict(x_test_transform)\n",
    "y_pred_tranformed2=clf2.predict(x_test_transform)\n",
    "#calculating the accuracy \n",
    "print('LR Accuracy=', accuracy_score(y_test, y_pred_tranformed1))\n",
    "print('DT Accuracy=', accuracy_score(y_test, y_pred_tranformed2))\n",
    "\n",
    "#5)CROSS VALIDATING THE RESULT FOR CONFIRMATION \n",
    "x_transformed=trf.fit_transform(x)\n",
    "clf1=LogisticRegression()\n",
    "clf2=DecisionTreeClassifier()\n",
    "print('LR',np.mean(cross_val_score(clf1, x_transformed, y, scoring='accuracy', cv=15)))\n",
    "print('DT',np.mean(cross_val_score(clf2, x_transformed, y, scoring='accuracy', cv=10)))\n",
    "\n",
    "#6) NOT CHecking QQ plot of BEFORE AND AFTER FUNCTIONTRANSFORM\n",
    "#before transform\n",
    "plt.figure(figsize=(9,2))\n",
    "plt.subplot(121)\n",
    "stats.probplot(x_train['fare'], dist='norm', plot=plt)\n",
    "#after Transform  \n",
    "plt.subplot(122)\n",
    "stats.probplot(x_train_transform['fare'], dist='norm', plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "5.Power Transformers\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "#Data Ingention \n",
    "df=pd.read_csv('concrete.csv')\n",
    "df.sample(2)\n",
    "df.info()\n",
    "# TRAIN-TEST SPLIT\n",
    "x=df.iloc[:, :-1]\n",
    "y=df.iloc[:, -1] \n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#BEFORE Transdormation: Trainig the model, predict, Accuracy \n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print('LR accuracy=', r2_score(y_test, y_pred))\n",
    "print('lr_crossvalidation', np.mean(cross_val_score(lr, x, y, scoring='r2', cv=10)))\n",
    "\n",
    "#Plotting the QQ plot \n",
    "for i in x_train.columns:\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.subplot(121)\n",
    "    sns.histplot(x_train[i], kde=True)\n",
    "    plt.title(i)\n",
    "    plt.subplot(122)\n",
    "    stats.probplot(x_train[i], dist='norm', plot=plt)\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "\n",
    "#TRANSFORMING \n",
    "pt=PowerTransformer(method='box-cox', standardize=True)\n",
    "x_train_transform= pt.fit_transform(x_train+0.000001)\n",
    "x_test_transform=pt.transform(x_test+0.000001)\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train_transform, y_train)\n",
    "y_pred_tranform=lr.predict(x_test_transform)\n",
    "\n",
    "print('LR accuracy after trans=', r2_score(y_test, y_pred_tranform))\n",
    "#cross validation after transform\n",
    "pt=PowerTransformer(method='box-cox', standardize=True)\n",
    "x_trans=pt.fit_transform(x+0.000001)\n",
    "print('LR_Trans_cross valid=', np.mean(cross_val_score(lr, x_trans, y, scoring='r2', cv=10)))\n",
    "\n",
    "#Ploting the graph Before and After Transformation \n",
    "x_trans = pd.DataFrame(x_trans, columns=x_train.columns)\n",
    "for i in x_trans.columns:\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.subplot(121)\n",
    "    sns.histplot(x_train[i], kde=True)\n",
    "    plt.title(f\"Original: {i}\")\n",
    "    plt.subplot(122)\n",
    "    column_index = x_train.columns.get_loc(i)  # Get the index of the column\n",
    "    sns.histplot(x_train_transform[:, column_index], kde=True)  # Use index\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: gold; text-align:left; font-size:200%; font-weight:bold;\">\n",
    "6.Quantile Transformers\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
